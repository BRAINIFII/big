# switch to Hadoop user
# Install scala-sbt via the latest command available in the terminal

echo "deb https://repo.scala-sbt.org/scalasbt/debian all main" | sudo tee /etc/apt/sources.list.d/sbt.list
echo "deb https://repo.scala-sbt.org/scalasbt/debian /" | sudo tee /etc/apt/sources.list.d/sbt_old.list
curl -sL "https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x2EE0EA64E40A89B84B2DF73499E82A75642AC823" | sudo apt-key add

sudo apt-get update
sudo apt-get install sbt

# enter sbt in the terminal to verify installation
# create the scala program for exception handling
> nano ExceptionHandlingTest.scala
# paste code

> nano exceptionhandlingtest.sbt
# create the sbt dependency file ‘exceptionhandlingtest.sbt’
#paste code

# start spark master & worker
> spark-master.sh
> start-worker.sh spark://192.46.209.57:7077/

# go back to the terminal pointing to the directory with scala and sbt file and create the sbt package
> sbt package


> spark-submit --class ExceptionHandlingTest.class --master spark://192.46.209.57:7077/ \target/scala-2.12/exceptionhandlingtest_2.12-1.0.jar